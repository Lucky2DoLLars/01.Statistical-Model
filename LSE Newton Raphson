## Computing LSE by using Newton-Raphson algorithm

H = function(n,x){
  return(2 * matrix(c(n, sum(x)
                  ,sum(x), sum(x^2)), 2,2)) }
  
grad = function(b,x,y){
  return(c(-2*sum(y-b[1]-b[2]*x),
           -2*sum(x*(y-b[1]-b[2]*x))))
}

LSE = function(b_old, data, y_idx, x_idx, iter.max = 50){
  iter = 0
  n = nrow(data)
  y = data[,y_idx]
  x = data[,x_idx]
  error = 10
  while( (iter <= iter.max) & (sum(abs(error)) > 1e-10) ){
    iter = iter + 1
    b_new = b_old - solve(H(n,x)) %*% grad(b_old,x,y)
    error = b_old - b_new
    b_old = b_new
  }
  return(c(beta = b_old, iter = iter))
}


## Check by comparing the result with the one from lm function in R

b_old = c(-100000,-100000)
print(LSE(b_old,iris,1,2,iter=10000))
print(lm(Sepal.Length ~ Sepal.Width,data = iris[,-5])$coefficients)
